{
 "metadata": {
  "name": "",
  "signature": "sha256:d754a39f8bc410368812ba950ae572de304eafbe3a4739e2931944b4c4bcd11f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "HUSTLING WITH SPARK"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 1: Spark and JSON file"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Section 1: Spark SQL with Json"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dispaly the Spark Context that is available to us since this was launched from the command line using:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<pyspark.context.SparkContext at 0x105d25f50>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a Spark Sql Context"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.sql import SQLContext\n",
      "sqlContext = SQLContext(sc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a spark context with a json dump from a mongo database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user = sqlContext.jsonFile(\"./data/user-bk.json\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Display the schema that was inferred from the json file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user.printSchema()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "root\n",
        " |-- _id: struct (nullable = true)\n",
        " |    |-- $oid: string (nullable = true)\n",
        " |-- description: string (nullable = true)\n",
        " |-- followers_count: integer (nullable = true)\n",
        " |-- friends_count: integer (nullable = true)\n",
        " |-- geo_enabled: boolean (nullable = true)\n",
        " |-- lang: string (nullable = true)\n",
        " |-- listed_count: integer (nullable = true)\n",
        " |-- location: string (nullable = true)\n",
        " |-- name: string (nullable = true)\n",
        " |-- protected: boolean (nullable = true)\n",
        " |-- screen_name: string (nullable = true)\n",
        " |-- statuses_count: integer (nullable = true)\n",
        " |-- time_zone: string (nullable = true)\n",
        " |-- user_id: string (nullable = true)\n",
        " |-- user_id_str: string (nullable = true)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a table named user_table to query from the user SQLContext object created earlier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user.registerTempTable(\"user_table\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a SQL Schema Resilient Distributed Dataset (RDD)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "users = sqlContext.sql(\"SELECT lang, count(lang) as total FROM user_table group by lang order by lang\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Display the results for the query with a loop"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for a in users.collect():\n",
      "    print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Row(lang=u'ar', total=6)\n",
        "Row(lang=u'de', total=12)\n",
        "Row(lang=u'en', total=1519)\n",
        "Row(lang=u'en-GB', total=3)\n",
        "Row(lang=u'en-gb', total=23)\n",
        "Row(lang=u'es', total=51)\n",
        "Row(lang=u'es-MX', total=1)\n",
        "Row(lang=u'fil', total=1)\n",
        "Row(lang=u'fr', total=18)\n",
        "Row(lang=u'he', total=1)\n",
        "Row(lang=u'id', total=18)\n",
        "Row(lang=u'it', total=9)\n",
        "Row(lang=u'ja', total=4)\n",
        "Row(lang=u'ko', total=2)\n",
        "Row(lang=u'msa', total=1)\n",
        "Row(lang=u'nl', total=10)\n",
        "Row(lang=u'pl', total=5)\n",
        "Row(lang=u'pt', total=18)\n",
        "Row(lang=u'ro', total=1)\n",
        "Row(lang=u'ru', total=3)\n",
        "Row(lang=u'sv', total=2)\n",
        "Row(lang=u'th', total=1)\n",
        "Row(lang=u'tr', total=5)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Section 2: Spark Resilient Distributed Dataset from Json"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a Spark Resilient Distibuted Dataset from a json file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user = sc.textFile(\"./data/user-bk.json\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a dataset were each element in the RDD is a dict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse JSON entries in dataset\n",
      "import json \n",
      "user_data = user.map(lambda line: json.loads(line))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Emit a key value pair for the purpose of tallying languages designated by twitter followers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_pared = user_data.map(lambda line: (line['lang'], 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Display the key value pairs emitted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in data_pared.take(30):\n",
      "    print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'th', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n",
        "(u'en', 1)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since en as a key is so common, Let's display the key value pairs emitted but this time filter out those with \"en\" as language"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for line in data_pared.filter(lambda x: x[0] != \"en\").take(30):\n",
      "    print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'th', 1)\n",
        "(u'en-gb', 1)\n",
        "(u'es', 1)\n",
        "(u'tr', 1)\n",
        "(u'ar', 1)\n",
        "(u'de', 1)\n",
        "(u'es', 1)\n",
        "(u'pt', 1)\n",
        "(u'en-gb', 1)\n",
        "(u'es', 1)\n",
        "(u'es', 1)\n",
        "(u'pt', 1)\n",
        "(u'ru', 1)\n",
        "(u'id', 1)\n",
        "(u'pt', 1)\n",
        "(u'es', 1)\n",
        "(u'de', 1)\n",
        "(u'pt', 1)\n",
        "(u'ko', 1)\n",
        "(u'es', 1)\n",
        "(u'es', 1)\n",
        "(u'es', 1)\n",
        "(u'de', 1)\n",
        "(u'es', 1)\n",
        "(u'ja', 1)\n",
        "(u'nl', 1)\n",
        "(u'sv', 1)\n",
        "(u'pt', 1)\n",
        "(u'es', 1)\n",
        "(u'es-MX', 1)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aggregate the language keys produced about to produce a tally"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from operator import add\n",
      "for item in data_pared.reduceByKey(add).sortByKey().collect():\n",
      "    print item"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'ar', 6)\n",
        "(u'de', 12)\n",
        "(u'en', 1519)\n",
        "(u'en-GB', 3)\n",
        "(u'en-gb', 23)\n",
        "(u'es', 51)\n",
        "(u'es-MX', 1)\n",
        "(u'fil', 1)\n",
        "(u'fr', 18)\n",
        "(u'he', 1)\n",
        "(u'id', 18)\n",
        "(u'it', 9)\n",
        "(u'ja', 4)\n",
        "(u'ko', 2)\n",
        "(u'msa', 1)\n",
        "(u'nl', 10)\n",
        "(u'pl', 5)\n",
        "(u'pt', 18)\n",
        "(u'ro', 1)\n",
        "(u'ru', 3)\n",
        "(u'sv', 2)\n",
        "(u'th', 1)\n",
        "(u'tr', 5)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to acheive the results above due to the RDD being a key value pair type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_pared = user_data.map(lambda line: (line['lang'], 1))\n",
      "data_pared.countByKey()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "defaultdict(<type 'int'>, {u'en': 1519, u'it': 9, u'ar': 6, u'id': 18, u'es': 51, u'en-gb': 23, u'ru': 3, u'nl': 10, u'pt': 18, u'tr': 5, u'th': 1, u'ro': 1, u'fil': 1, u'en-GB': 3, u'fr': 18, u'de': 12, u'ja': 4, u'he': 1, u'ko': 2, u'sv': 2, u'es-MX': 1, u'pl': 5, u'msa': 1})"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 2:  Spark and Log Text File"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Section 1: Spark Resilient Distributed Dataset with Log Text File"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a Spark Resilient Distributed DataSet (RDD) from the Log File\n",
      "i.e. one log entry/line per element in the iterator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logFile = \"./data/hardhittinent_logs-Oct-2014.txt\"\n",
      "logData = sc.textFile(logFile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filter out the line lines we do not want.\n",
      "Keep the lines of interest i.e. those containing \"utm_campaign=worldstarhiphop\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "campaign = \"utm_campaign=worldstarhiphop\"\n",
      "campaign_data = logData.filter(lambda x: campaign in x.split(\" \")[6])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function below is used to get a datetime object from the data harnessed form the log file entry"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime\n",
      "def get_dates(string_date):\n",
      "    #string_date = '30/Sep/2014:05:39:30'\n",
      "    date_object = datetime.strptime(string_date, '%d/%b/%Y:%H:%M:%S')\n",
      "    return date_object"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function takes a log entry parses it an emits the hour an event occured plus the person of credit\n",
      "there are definately better time-tested recipes parsing logs ;-)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "def get_person_of_credit_and_datetime(text):\n",
      "    exploded_text = text.split(\" \")\n",
      "    url = exploded_text[6]\n",
      "\n",
      "    pattern = 'utm_source='\n",
      "    match = re.search(pattern, url)\n",
      "    e = match.end()\n",
      "    \n",
      "    person = url[e:]\n",
      "    date = exploded_text[3][1:]\n",
      "\n",
      "\n",
      "    return person, get_dates(date)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Transform the RDD with by creating a key-value pair of person of credit - datetime"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "utm_source_by_person_of_credit_time = campaign_data.map(lambda x: get_person_of_credit_and_datetime(x))\n",
      "for x in utm_source_by_person_of_credit_time.take(20):\n",
      "    print x\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 52))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 52))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 52))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 52))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 52))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 53))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 53))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 54))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 57))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 58))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 39, 59))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 40, 28))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 40, 52))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 46, 7))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 47, 44))\n",
        "(u'oski', datetime.datetime(2014, 9, 30, 9, 48, 31))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 54, 24))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 9, 55, 55))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 10, 53, 1))\n",
        "(u'wiz', datetime.datetime(2014, 9, 30, 11, 3, 24))\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Further transform the dataset by getting the hour component"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "utm_source_by_person_of_credit_and_hour = utm_source_by_person_of_credit_time.map(lambda x: (x[0], x[1].hour))\n",
      "for x in utm_source_by_person_of_credit_and_hour.take(20):\n",
      "    print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'oski', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 9)\n",
        "(u'wiz', 10)\n",
        "(u'wiz', 11)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Further transform the dataset by getting the day of month component"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "utm_source_by_person_of_credit_and_hour = utm_source_by_person_of_credit_time.map(lambda x: (x[0], x[1].day))\n",
      "for x in utm_source_by_person_of_credit_and_hour.take(20):\n",
      "    print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'oski', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n",
        "(u'wiz', 30)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a RDD where the data is aggragated the person of interest and hour bin by key (in this case person of iterest)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in utm_source_by_person_of_credit_and_hour.groupByKey().collect():\n",
      "    a = [i for i in x[1]]\n",
      "    print x[0], a\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "oski [30, 1, 3, 3, 6, 13, 19, 22, 22, 29]\n",
        "wiz [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 6, 6, 8, 10, 10, 16, 16, 17, 22, 22, 27, 30]\n"
       ]
      }
     ],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}